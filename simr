#!/bin/bash

############################################################
# Set this if the hadoop binary/script is not in the PATH  #
# HADOOP=/root/hadoop/bin/hadoop                           #
############################################################

INPATH=$(type -P "hadoop") 
PROGNAME=$(basename $0)
SIMRJAR="simr.jar"

if [ -f "$INPATH" ]; then
  HADOOPBIN=$INPATH
elif [ -n "$HADOOP" -a -f "$HADOOP"  ]; then
  HADOOPBIN=$HADOOP
elif [ -n "$HADOOP" -a -f "$HADOOP/bin/hadoop" ]; then
  HADOOPBIN="$HADOOP/bin/hadoop"
elif [ -n "$HADOOP" -a -f "$HADOOP/hadoop" ]; then
  HADOOPBIN="$HADOOP/hadoop"
fi

if [ ! -f "$HADOOPBIN" ];
then
   echo -e "Error:\n  Couldn't find the hadoop executable, add it to the PATH or point \$HADOOP to it."
   exit 1
fi

if [ "$#" -le 1 ];
then
  echo "Usage:"
  echo "  $PROGNAME [--size=N] [--memory=N] <hdfs_out_dir> <your_spark_jar> <main_class_name> <parameters>"
  echo ""
  echo "  <parameters> will be passed to your <main_class_name>, with %spark_url%"
  echo "      replaced with the Spark URL that must be passed to SparkContext."
  echo ""
  echo "      --size can optionally be set to indicate the size of the cluster."
  echo ""
  echo "      --memory can optionally be used to set memory for each executor (map task)"
  echo ""
  echo "  $PROGNAME [--size=N] --shell <hdfs_out_dir>"
  echo ""
  echo "  Run $PROGNAME with an interactive shell."
  echo ""
  exit 1
fi

OUTDIR=$1
USERJAR=$2

if [ -a "$USERJAR" ];
then
  USERJAR=$(readlink -e $USERJAR)
fi

shift
shift

cd "`dirname $0`"

if [ ! -f "$SIMRJAR" ];
then
  echo -e "Error:\n " \
          "  Couldn't locate $SIMRJAR, make sure it exists in the same directory as this script"
  exit 1
fi

fsize=$(ls -1hl $SIMRJAR | cut -d " " -f 5)
echo "Uploading $SIMRJAR ($fsize) to the Hadoop cluster, this may take a while"

HADOOP_USER_CLASSPATH_FIRST=1 HADOOP_CLASSPATH=$SIMRJAR exec $HADOOPBIN jar $SIMRJAR $OUTDIR $USERJAR $@
